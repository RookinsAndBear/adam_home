{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome new ADAM user!\n",
    "\n",
    "   This notebook will guide you through a few ADAM features and validate that your system is configured correctly.\n",
    "   This guide will demonstate how to pull orbital data for a given asteroid and time frame from JPL Horizons and how to propogate that same orbit using ADAM.  This program will also allow the user to create plots to compare the orbital data from the two sources as well as provide multiple ways to export the data for other applications. \n",
    "    \n",
    "\n",
    "   Before starting this notebook, you should have already run the config_demo.ipynb notebook on your system (located in adam_home/demos).  Additionally, please ensure that you have installed Astroquery on your system (instructions in FAQ).    \n",
    "   \n",
    "   \n",
    "Currently, as of 25-MAR-19, this notebook supports the following features. \n",
    "\n",
    "-Pulls trajectory data for a given object and timeframe from NASA JPL\n",
    "\n",
    "-Propagates trajectory for that same object in ADAM. \n",
    "\n",
    "-Plots orbits for ADAM and JPL data.  \n",
    "\n",
    "-Exports ADAM Data in CSV format\n",
    "\n",
    "-Exports JPL Data in CSV format\n",
    "\n",
    "-Calculates and displays RIC for ADAM vs JPL\n",
    "\n",
    "- Exports ADAM ephemeris as .e file. \n",
    "\n",
    "\n",
    "In Development\n",
    "\n",
    "- Transform ADAM data to rotate from EMEME2000 to ICRF\n",
    "\n",
    "- Add option to output JPL data as .e \n",
    "\n",
    "\n",
    "NOTES: \n",
    "\n",
    "-This version currently defaults to the dev server since, as of 07-MAR-19, the production side is pending updates.\n",
    "\n",
    "-This version is written to read the astro folder from within \"adam_home\".  You may need to point the code in the next cell to your Astro folder.    \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  These first cells must be run in order any time you operate the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions (for demo purposes) (will be a seperate file in standard notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Transform Functions\n",
    "# These will later be in a seperate file\n",
    "\n",
    "\"\"\"\n",
    "    transform.py\n",
    "\n",
    "    Sources:\n",
    "    Vallado, David - Fundamentals of Astrodynamics and Applications\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from math import sin, cos, acos, sqrt\n",
    "\n",
    "TOL = 1.0e-10\n",
    "TWO_PI = 2 * np.pi\n",
    "\n",
    "class Transform(object):\n",
    "    \"\"\"\n",
    "    Does all transformations, including between coordinate systems\n",
    "    TODO: add unit tests\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize attributes\n",
    "        \"\"\"\n",
    "        self._mu = 132712440018.0  # sun gravitational parameter, km^3/s^2\n",
    "\n",
    "    def set_gravitational_parameter(self, mu):\n",
    "        \"\"\"\n",
    "        Set the gravitational parameter of interest\n",
    "\n",
    "        Args:\n",
    "            mu (float) - standard gravitational parameter, km^3/s^2\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self._mu = mu\n",
    "\n",
    "    def Rotx(self, angle):\n",
    "        \"\"\"\n",
    "        Returns the transformation corresponding to the rotation about the x-axis\n",
    "        by an angle.\n",
    "\n",
    "        Args:\n",
    "            angle (float) - angle in radians\n",
    "\n",
    "        Returns:\n",
    "            R (numpy matrix) - rotation matrix\n",
    "        \"\"\"\n",
    "        cosangle = cos(angle)\n",
    "        sinangle = sin(angle)\n",
    "\n",
    "        # Return rotation matrix\n",
    "        R = np.array([[1, 0, 0], \\\n",
    "                      [0, cosangle, sinangle], \\\n",
    "                      [0, -sinangle, cosangle]])\n",
    "        return R\n",
    "\n",
    "    def Roty(self, angle):\n",
    "        \"\"\"\n",
    "        Returns the transformation corresponding to the rotation about the y-axis\n",
    "        by an angle.\n",
    "\n",
    "        Args:\n",
    "            angle (float) - angle in radians\n",
    "\n",
    "        Returns:\n",
    "            R (numpy matrix) - rotation matrix\n",
    "        \"\"\"\n",
    "        cosangle = cos(angle)\n",
    "        sinangle = sin(angle)\n",
    "\n",
    "        # Return rotation matrix:\n",
    "        R = np.array([[cosangle, 0, -sinangle], \\\n",
    "                      [0, 1, 0], \\\n",
    "                      [sinangle, 0, cosangle]])\n",
    "        return R\n",
    "\n",
    "    def Rotz(self, angle):\n",
    "        \"\"\"\n",
    "        Returns the transformation corresponding to the rotation about the z-axis\n",
    "        by an angle.\n",
    "\n",
    "        Args:\n",
    "            angle (float) - angle in radians\n",
    "\n",
    "        Returns:\n",
    "            R (numpy matrix) - rotation matrix\n",
    "        \"\"\"\n",
    "        cosangle = cos(angle)\n",
    "        sinangle = sin(angle)\n",
    "\n",
    "        # Return rotation matrix:\n",
    "        R = np.array([[cosangle, sinangle, 0], \\\n",
    "                      [-sinangle, cosangle, 0], \\\n",
    "                      [0, 0, 1]])\n",
    "        return R\n",
    "\n",
    "    def classical_to_cartesian(self, a, e, i, node, w, TA):\n",
    "        \"\"\" Convert classical elements to cartesian elements\n",
    "\n",
    "        Args:\n",
    "            a (float) = semi-major axis (km)\n",
    "            e (float) = eccentricity\n",
    "            i (float) = inclination (0-pi rad)\n",
    "            node (float) = right ascension of ascending node (0-2pi rad)\n",
    "            w (float) = argument of periapsis (0-2pi rad)\n",
    "            TA (float) = true anomaly (0-2pi rad)\n",
    "\n",
    "        Returns:\n",
    "            r (numpy array) - cartesian position (km)\n",
    "            v (numpy array) - cartesian velocity (km/s)\n",
    "        \"\"\"\n",
    "        # Convert\n",
    "        p = a * (1 - e ** 2)  # semi-latus rectum, km\n",
    "\n",
    "        # Determine what type of orbit is involved and set up angles for special cases\n",
    "        if e < TOL:\n",
    "            # argument of periapsis and RAAN are 0 for circular orbits\n",
    "            w = 0.0\n",
    "            # Circular equatorial\n",
    "            if (i < TOL) or (abs(i - np.pi) < TOL):\n",
    "                node = 0.0\n",
    "        # Elliptical equatorial\n",
    "        elif (i < TOL) or (abs(i - np.pi) < TOL):\n",
    "            node = 0.0\n",
    "\n",
    "        # Position and velocity vectors in perifocal coordinate system\n",
    "        r_pqw = [0.0] * 3\n",
    "        v_pqw = [0.0] * 3\n",
    "        temp = p / (1.0 + e * cos(TA))\n",
    "        r_pqw[0] = temp * cos(TA)\n",
    "        r_pqw[1] = temp * sin(TA)\n",
    "\n",
    "        if abs(p) < 0.0001:\n",
    "            p = 0.0001\n",
    "\n",
    "        v_pqw[0] = -sin(TA) * sqrt(self._mu) / sqrt(p)\n",
    "        v_pqw[1] = (e + cos(TA)) * sqrt(self._mu) / sqrt(p)\n",
    "\n",
    "        # Transform to cartesian\n",
    "        tempvec = self.Rotz(-w).dot(r_pqw)\n",
    "        tempvec = self.Rotx(-i).dot(tempvec)\n",
    "        r = self.Rotz(-node).dot(tempvec)\n",
    "\n",
    "        tempvec = self.Rotz(-w).dot(v_pqw)\n",
    "        tempvec = self.Rotx(-i).dot(tempvec)\n",
    "        v = self.Rotz(-node).dot(tempvec)\n",
    "\n",
    "        return r, v\n",
    "\n",
    "    def cartesian_to_classical(self, r, v):\n",
    "        \"\"\" Convert cartesian elements to classical elements\n",
    "\n",
    "        Args:\n",
    "            r (list or array) - cartesian position (km)\n",
    "            v (list or array) - cartesian velocity (km/s)\n",
    "\n",
    "        Returns:\n",
    "            a (float) = semi-major axis (km)\n",
    "            e (float) = eccentricity\n",
    "            i (float) = inclination (0-pi rad)\n",
    "            node (float) = right ascension of ascending node (0-2pi rad)\n",
    "            w (float) = argument of periapsis (0-2pi rad)\n",
    "            TA (float) = true anomaly (0-2pi rad)\n",
    "        \"\"\"\n",
    "\n",
    "        # Ensure r, v are numpy arrays\n",
    "        r = np.array(r)\n",
    "        v = np.array(v)\n",
    "\n",
    "        # Get magnitudes of r, v\n",
    "        mag_r = np.linalg.norm(r)\n",
    "        mag_v = np.linalg.norm(v)\n",
    "\n",
    "        # Find h, n, and e vectors\n",
    "        hbar = np.cross(r, v)  # angular momentum vector\n",
    "        mag_h = np.linalg.norm(hbar)\n",
    "\n",
    "        nbar = np.array([0.0] * 3)  # line of nodes\n",
    "        ebar = np.array([0.0] * 3)  # eccentricity vector\n",
    "\n",
    "        if mag_h > TOL:\n",
    "\n",
    "            # Define line of nodes\n",
    "            nbar[0] = -hbar[1]\n",
    "            nbar[1] = hbar[0]\n",
    "            mag_n = np.linalg.norm(nbar)\n",
    "            c1 = mag_v ** 2 - self._mu / mag_r\n",
    "\n",
    "            # Get eccentricity\n",
    "            for i in range(3):\n",
    "                ebar[i] = (c1 * r[i] - (r.dot(v)) * v[i]) / self._mu\n",
    "\n",
    "            e = np.linalg.norm(ebar)\n",
    "\n",
    "            # Get semi-major axis\n",
    "            a = 0.5 * mag_v ** 2 - self._mu / mag_r\n",
    "            if abs(a) > TOL:\n",
    "                a = -self._mu / (2 * a)\n",
    "            else:\n",
    "                a = float('nan')\n",
    "\n",
    "            # Get inclination\n",
    "            i = acos(hbar[2] / mag_h)\n",
    "\n",
    "            # Get right ascension of ascending node\n",
    "            if mag_n > TOL:\n",
    "                temp = nbar[0] / mag_n\n",
    "                if abs(temp) > 1.:\n",
    "                    temp = np.sign(temp)\n",
    "                node = acos(temp)\n",
    "                if nbar[2] <= 0.:\n",
    "                    node = TWO_PI - node\n",
    "            else:\n",
    "                node = float('nan')\n",
    "\n",
    "            # Get argument of periapsis and true anomaly\n",
    "            if e > TOL:\n",
    "                w = acos((nbar.dot(ebar)) / (mag_n * e))\n",
    "                TA = acos((ebar.dot(r)) / (e * mag_r))\n",
    "                if ebar[2] < 0.:\n",
    "                    w = TWO_PI - w\n",
    "                if r.dot(v) < 0.:\n",
    "                    TA = TWO_PI - TA\n",
    "            else:\n",
    "                w = float('nan')\n",
    "                TA = float('nan')\n",
    "        else:\n",
    "            a = float('nan')\n",
    "            e = float('nan')\n",
    "            i = float('nan')\n",
    "            node = float('nan')\n",
    "            w = float('nan')\n",
    "            TA = float('nan')\n",
    "\n",
    "        return a, e, i, node, w, TA\n",
    "    \n",
    "\n",
    "    def ICRF_to_EMEME2000(vec_iX,vec_iY,vec_iZ):\n",
    "        # Convert the obliquity from arcseconds to degrees and then to radians for Python\n",
    "        obliquity = np.deg2rad(84381.448/3600.0)\n",
    "           \n",
    "        # rotation angle phi\n",
    "        phi = obliquity\n",
    "        \n",
    "        # The final (rotated) vector\n",
    "        vec_fX  =  vec_iX\n",
    "        vec_fY  =  vec_iY*np.cos(phi)+ vec_iZ*np.sin(phi)\n",
    "        vec_fZ  = -(vec_iY*np.sin(phi)) + vec_iZ*np.cos(phi)\n",
    "\n",
    "        return vec_fX, vec_fY, vec_fZ \n",
    "\n",
    "\n",
    "    def EMEME2000_to_ICRF(vec_iX,vec_iY,vec_iZ):\n",
    "                # Convert the obliquity from arcseconds to degrees and then to radians for Python\n",
    "        obliquity = np.deg2rad(84381.448/3600.0)\n",
    "            \n",
    "        # rotation angle phi \n",
    "        phi = -(obliquity) \n",
    "        \n",
    "        # The final (rotated) vector\n",
    "        vec_fX  =  vec_iX\n",
    "        vec_fY  =  vec_iY*np.cos(phi)+ vec_iZ*np.sin(phi)\n",
    "        vec_fZ  = -(vec_iY*np.sin(phi)) + vec_iZ*np.cos(phi)\n",
    "\n",
    "        return vec_fX, vec_fY, vec_fZ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Transform Functions\n",
    "# These will later be in a seperate file\n",
    "\n",
    "\"\"\"\n",
    "    asteroid_database.py\n",
    "\n",
    "    Wrapper for the astroquery JPL Horizons API\n",
    "    Does all conversions and returns relevant information\n",
    "\"\"\"\n",
    "\n",
    "from astroquery.jplhorizons import Horizons\n",
    "\n",
    "AU = 149597870.0     # conversion from AU to km\n",
    "DAY2SEC = 24*60*60   # conversion from days to seconds\n",
    "\n",
    "class AsteroidDB(object):\n",
    "    \"\"\"\n",
    "    Grabs asteroid ephemerides from JPL Horizons database\n",
    "    TODO: add orbital elements return, unit tests\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize attributes\n",
    "        \"\"\"\n",
    "        self._step = 1           # step size\n",
    "        self._step_unit = 'day'  # step size unit\n",
    "\n",
    "    def set_step_size(self, step, step_unit):\n",
    "        \"\"\"\n",
    "        Set step size and step size unit\n",
    "        Unit options are:\n",
    "        sec, min, day, hour, year\n",
    "\n",
    "        Args:\n",
    "            step (int) - step size\n",
    "            step_unit (str) - unit for step size\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        options = ['sec', 'min', 'day', 'hour', 'year']\n",
    "\n",
    "        if step_unit not in options:\n",
    "            raise KeyError(\"Invalid units. Options are: %s\" % options)\n",
    "\n",
    "        # Enforce integer step\n",
    "        step = int(step)\n",
    "\n",
    "        self._step = step\n",
    "        self._step_unit = step_unit\n",
    "\n",
    "    def get_cartesian_states(self, obj_id, epoch, end_time):\n",
    "        \"\"\"\n",
    "        Query database and get cartesian rv\n",
    "        NOTE: id requires the Horizons name, not SPK number!\n",
    "\n",
    "        Args:\n",
    "            id (str) - object ID (Horizons name)\n",
    "            epoch (datetime obj) - start time\n",
    "            end_time (datetime obj) - end time\n",
    "\n",
    "        Returns:\n",
    "            rv (list of rv list) - rv in the format:\n",
    "                x (km), y (km), z (km), vx (km/s), vy (km/s), vz (km/s)\n",
    "        \"\"\"\n",
    "        # Format step size for query\n",
    "        if self._step_unit == 'sec':\n",
    "            # Special formatting needed\n",
    "            dt = int((end_time - epoch).total_seconds()/self._step)\n",
    "        else:\n",
    "            # Concatenate step size and unit\n",
    "            dt = str(self._step)+self._step_unit[0]\n",
    "\n",
    "        # Make call to JPL Horizons database and get data\n",
    "        try:\n",
    "            obj = Horizons(id=obj_id, location='@sun',\n",
    "                           epochs={'start': epoch.isoformat(),\n",
    "                                   'stop': end_time.isoformat(),\n",
    "                                   'step': dt})\n",
    "            data = obj.vectors()\n",
    "        except:\n",
    "            raise RuntimeError(\"Invalid query\")\n",
    "\n",
    "        # Get column header\n",
    "        columns = data.colnames\n",
    "\n",
    "        # Make state vectors\n",
    "        rv = []\n",
    "        for row in data:\n",
    "            r_mult = AU          # convert AU to km\n",
    "            v_mult = AU/DAY2SEC  # convert AU/day to km/s\n",
    "\n",
    "            rv.append([row[columns.index(\"x\")]*r_mult,\n",
    "                       row[columns.index(\"y\")]*r_mult,\n",
    "                       row[columns.index(\"z\")]*r_mult,\n",
    "                       row[columns.index(\"vx\")]*v_mult,\n",
    "                       row[columns.index(\"vy\")]*v_mult,\n",
    "                       row[columns.index(\"vz\")]*v_mult])\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This imports libraries from ADAM and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This specifies the path to the adam_home folder and configuration file on your system.\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "adam_home_defined = expanduser(\"~\") + \"/adam_home\" # default location\n",
    "config_folder=expanduser(\"~\") + \"/adam_home/config\" # default location  # Works,  19 Feb -LRH\n",
    "import adam\n",
    "\n",
    "# This imports the necessary libraries from ADAM and JPL as well as other packages. \n",
    "from adam import Batch\n",
    "from adam import Batches\n",
    "from adam import BatchRunManager\n",
    "from adam import PropagationParams\n",
    "from adam import OpmParams\n",
    "from adam import ConfigManager\n",
    "from adam import Projects\n",
    "from adam import RestRequests\n",
    "from adam import AuthenticatingRestProxy\n",
    "import time\n",
    "import os\n",
    "from adam import Service\n",
    "from adam import Batch\n",
    "from adam import PropagationParams\n",
    "from adam import OpmParams\n",
    "from adam import BatchRunManager\n",
    "from adam import ConfigManager\n",
    "import unittest\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.testing as npt\n",
    "from adam.batch import StateSummary\n",
    "from adam.batch import PropagationResults\n",
    "\n",
    "#Astro Query\n",
    "from astroquery.jplhorizons import Horizons\n",
    "from astroquery.jplhorizons import conf\n",
    "conf.horizons_server = 'https://ssd.jpl.nasa.gov/horizons_batch.cgi'\n",
    "\n",
    "\n",
    "\n",
    "#NOTE: This version is written to read the astro folder from within \"adam_home\". You may need to move astro to this folder. \n",
    "#If the astro folder is not in adam_home, please modify the next line to point to your \"astro\" folder. \n",
    "#sys.path.insert(0,'C:\\\\Users\\\\Lowell\\\\adam_home\\\\astro') \n",
    "#astro Lib\n",
    "\n",
    "\n",
    "# These will be kept when calling astro from its own folder\n",
    "#from astro import Transform\n",
    "#from astro import asteroid_database\n",
    "  \n",
    "\n",
    "\n",
    "#Other Lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "\n",
    "# Define Constants\n",
    "GM = 132712440041.93938   #From JPL Horizons\n",
    "AU_Meters = 1.49597870e+11  # Astronomical Units in meters  \n",
    "AU_Km = 149597870.0     # conversion from AU to km \n",
    "AU_per_day = 1731456.84 # AU/Day converted to Meters per second\n",
    "# From NASA JPL.  The astronomical unit (au) is defined by the IAU as exactly 149,597,870,700 m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Asteroid and time frame, pull data from JPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Enter asteroid target number. e.g for Eros use 433. IDs can be searched here: https://ssd.jpl.nasa.gov/sbdb.cgi#top \")\n",
    "asteroid = input() #in form of target number i.e. for Eros use 433  #10 Hygiea\n",
    "\n",
    "# You can edit the inputs below to change the start/stop times and the step size. \n",
    "start_time_str='2016-10-04T00:00:00' #YYYY-Mon-Dy {HH:MM}   #Default: start_time_str='2016-10-04T00:00:00'\n",
    "end_time_str='2017-10-11T00:00:00'   # Default: end_time_str='2017-10-11T00:00:00'\n",
    "step = '1d'   #Default:  1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#call the object's data from JPL\n",
    "\n",
    "# Original\n",
    "obj = Horizons(id=str(asteroid), location=None ,epochs={'start':start_time_str, 'stop':end_time_str,'step':step})\n",
    "vec = obj.vectors() #state vector at each epoch, inital state vector is initial epoch\n",
    "#vec is the entire epheremris over the specified timeframe, the inital state vector (to be put into ADAM) is vec's first row\n",
    "\n",
    "#call the object's data from JPL  # Fails when sent to ADAM\n",
    "# For Geocentric TESTING\n",
    "#obj = Horizons(id=str(asteroid), location='Geocentric'  ,epochs={'start':start_time_str, 'stop':end_time_str,'step':step})\n",
    "#vec = obj.vectors() #state vector at each epoch, inital state vector is initial epoch\n",
    "# tried location='Geocentric'   Didn't work when sending to ADAM\n",
    "# Trying location=500   # Fails when submitting to ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simplified Dataframe\n",
    "\n",
    "eph_JPL_df = pd.DataFrame(\n",
    "    {'Time [Barycentric TBD]': vec['datetime_jd'],\n",
    "     'x [m]': vec['x']*AU_Meters,#1.496e+11,\n",
    "     'y [m]': vec['y']*AU_Meters,#1.496e+11,\n",
    "     'z [m]': vec['z']*AU_Meters,#1.496e+11,\n",
    "     'x_dot [m/s]': vec['vx']*AU_per_day,#1731456.84,\n",
    "     'y_dot [m/s]': vec['vy']*AU_per_day ,#1731456.84,\n",
    "     'z_dot [m/s]': vec['vz']*AU_per_day, #1731456.84\n",
    "     \n",
    "    })\n",
    "# eph_JPL_df    # Commented out to improve readibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Organize JPL Data to submit state vector to ADAM. \n",
    "\n",
    "#JPL Cartesian State Vector + Data Frame\n",
    "JPL_SV = np.array([vec[i][0] for i in vec.columns])\n",
    "JPL_SV_df_cart = pd.DataFrame(JPL_SV, index= vec.columns, columns=list(' ')) \n",
    "#JPL r and v vectors\n",
    "JPL_r = np.array([np.float(i) for i in JPL_SV[5:8]])*AU_Km#1.496e+8\n",
    "JPL_v = np.array([np.float(i) for i in JPL_SV[8:11]])*(AU_per_day/1000) # KM per second  1731.46\n",
    "print(\"Position: %s km\" % JPL_r)\n",
    "print(\"Velocity: %s km/s\" % JPL_v)\n",
    "#########################################################################\n",
    "#Converting to Keplerian \n",
    "d2r = np.pi/180.\n",
    "r2d = 180./np.pi\n",
    "trans = Transform()\n",
    "\n",
    "JPL_a, JPL_e, JPL_i, JPL_node, JPL_w, JPL_TA = trans.cartesian_to_classical(JPL_r,JPL_v)\n",
    "kep_col = np.array(['SMA','Ecc','Inc','RAAN','Arg of per','True anomaly'])\n",
    "\n",
    "JPL_SV_df_kep = pd.DataFrame(np.array([JPL_a, JPL_e, JPL_i*r2d, JPL_node*r2d, JPL_w*r2d, JPL_TA*r2d]), index= kep_col, columns=list(' ')) \n",
    "#Combining two dataframes\n",
    "JPL_SV_df = pd.concat([JPL_SV_df_cart, JPL_SV_df_kep], axis=0) \n",
    "# JPL_SV_df  # Again, commented out to avoid excessive outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Minor Planet Center Queries\n",
    "\n",
    "#Redundant?\n",
    "\n",
    "#from astroquery.mpc import MPC\n",
    "#mpc = MPC()\n",
    "#result = mpc.query_object_async(number=asteroid, target_type=\"asteroid\")\n",
    "\n",
    "\n",
    "#result.json()   # Remove # to see results\n",
    "#[{'absolute_magnitude': '3.34', 'aphelion_distance': '2.976', 'arc_length': 79247, 'argument_of_perihelion': '73.11528', 'ascending_node': '80.3099167', 'critical_list_numbered_object': False, 'delta_v': 10.5, 'designation': None, 'earth_moid': 1.59353, 'eccentricity': '0.0755347', 'epoch': '2018-03-23.0', 'epoch_jd': '2458200.5', 'first_observation_date_used': '1801-01-31.0', 'first_opposition_used': '1801', 'inclination': '10.59351', 'jupiter_moid': 2.09509, 'km_neo': False, 'last_observation_date_used': '2018-01-20.0', 'last_opposition_used': '2018', 'mars_moid': 0.939285, 'mean_anomaly': '352.23052', 'mean_daily_motion': '0.2141308', 'mercury_moid': 2.18454, 'name': 'Ceres', 'neo': False, 'number': 1, 'observations': 6689, 'oppositions': 114, 'orbit_type': 0, 'orbit_uncertainty': '0', 'p_vector_x': '-0.87827466', 'p_vector_y': '0.33795664', 'p_vector_z': '0.33825868', 'perihelion_date': '2018-04-28.28378', 'perihelion_date_jd': '2458236.78378', 'perihelion_distance': '2.5580384', 'period': '4.6', 'pha': False, 'phase_slope': '0.12', 'q_vector_x': '-0.44248615', 'q_vector_y': '-0.84255514', 'q_vector_z': '-0.30709419', 'residual_rms': '0.6', 'saturn_moid': 6.38856, 'semimajor_axis': '2.7670463', 'tisserand_jupiter': 3.3, 'updated_at': '2018-02-26T17:29:46Z', 'uranus_moid': 15.6642, 'venus_moid': 1.84632}]\n",
    "#MPC Eph database\n",
    "#https://minorplanetcenter.net/iau/MPEph/MPEph.html?format=json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagate through ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reads your config from a file in current directory. For instructions on setting this up, see config_demo notebook.\n",
    "config = ConfigManager(config_folder + '/adam_config.json').get_config(\"dev\")  # remove \"dev\" to default to prod\n",
    "service = Service(config)\n",
    "service.setup()\n",
    "auth_rest = AuthenticatingRestProxy(RestRequests(config.get_url()), config.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_project = service.new_working_project() # cleans up old batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Keplerian Parameters\n",
    "start_time_str_Z=start_time_str+'Z'\n",
    "end_time_str_Z=end_time_str+'Z'\n",
    "\n",
    "#keplerian Method:\n",
    "keplerian_elements = {\n",
    "    'semi_major_axis_km': np.float(JPL_SV_df.iat[14,0]),\n",
    "    'eccentricity': np.float(JPL_SV_df.iat[15,0]),\n",
    "    'inclination_deg': np.float(JPL_SV_df.iat[16,0]),\n",
    "    'ra_of_asc_node_deg': np.float(JPL_SV_df.iat[17,0]),\n",
    "    'arg_of_pericenter_deg': np.float(JPL_SV_df.iat[18,0]),\n",
    "    'true_anomaly_deg': np.float(JPL_SV_df.iat[19,0]),\n",
    "    'gm': 132712440041.93938 # FROM JPL Horizons                                    \n",
    "}\n",
    "propagation_params = PropagationParams({\n",
    "    'start_time': start_time_str_Z,\n",
    "    'end_time': end_time_str_Z,\n",
    "    'project_uuid': config.get_workspace(),\n",
    "    'description': 'Created by test at ' + start_time_str\n",
    "})\n",
    "opm_params_templ = {\n",
    "    'epoch': start_time_str_Z,\n",
    "    'object_name': (JPL_SV_df.iat[0,0]),    # object ID\n",
    "    'object_id':asteroid\n",
    "    #'comment':\"Keplerian Coord System\"                    \n",
    "    # state_vector or keplerian_elements will be set later.\n",
    "    #'mass': 500.5,\n",
    "    #'solar_rad_area': 25.2,\n",
    "    #'solar_rad_coeff': 1.2,\n",
    "    #'drag_area': 33.3,\n",
    "    #'drag_coeff': 2.5\n",
    "}\n",
    "###################################################################################\n",
    "\n",
    "### Eventually we want to define and call these functions from elsewhere. \n",
    "#Create keplerian batch files to be put into ADAM\n",
    "def make_keplerian_batches(start_time_str, end_time_st):\n",
    "    keplerian_opm_params = opm_params_templ.copy()\n",
    "    keplerian_opm_params['keplerian_elements'] = keplerian_elements\n",
    "\n",
    "    keplerian = Batch(propagation_params, OpmParams(keplerian_opm_params))\n",
    "    return  keplerian\n",
    "\n",
    "\n",
    "kep_batch= make_keplerian_batches(start_time_str, end_time_str)\n",
    "print(kep_batch.get_opm_params().generate_opm())\n",
    "\n",
    "# Submit and wait until batch run is ready\n",
    "batches_module = Batches(auth_rest)\n",
    "BatchRunManager(batches_module, [kep_batch]).run()\n",
    "\n",
    "###################################################################################\n",
    "# Retrieve the vector at the end of the state\n",
    "def kep_single_run(self, start_time_str, end_time_str):\n",
    "    \n",
    "    #start_time_str = start.isoformat() + 'Z'\n",
    "    #end_time_str = end.isoformat() + 'Z'\n",
    "\n",
    "    keplerian = make_keplerian_batches(start_time_str, end_time_str) #batch objets\n",
    "    print(keplerian.get_state_summary().get_parts_count())\n",
    "\n",
    "    BatchRunManager(self.service.get_batches_module(), [kep_batch]).run()\n",
    "\n",
    "    keplerian_end_state = kep_batch.get_results().get_end_state_vector()\n",
    "    return keplerian_end_state\n",
    "\n",
    "# Get the end state vector \n",
    "end_state_vector = kep_batch.get_results().get_end_state_vector()\n",
    "print(\"State vector at the end of propagation:\")\n",
    "print(end_state_vector)\n",
    "###################################################################################\n",
    "#Get status and parts count\n",
    "parts_count = kep_batch.get_state_summary().get_parts_count()\n",
    "print(\"Final state: %s, part count %s\\n\" % (kep_batch.get_calc_state(), parts_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull ephemeris from ADAM results and organize into data frames.\n",
    "part_to_get = 0\n",
    "eph = kep_batch.get_results().get_parts()[part_to_get].get_ephemeris()\n",
    "\n",
    "_ ,eph_temp = eph.split(\"EphemerisTimePosVel\\n\\n\", 1)\n",
    "eph_temp, _ = eph_temp.split(\"\\n\\nEND Ephemeris\", 1)\n",
    "eph_temp\n",
    "\n",
    "eph_temp_split=eph_temp.split(' ')\n",
    "#eph_temp_split\n",
    "\n",
    "eph_split_fix=[]\n",
    "atomic_times=[]\n",
    "atomic_times.append(np.float(eph_temp_split[0]))\n",
    "for i in range(1, len(eph_temp_split[0::6])-1):\n",
    "    #calculate atomic time\n",
    "    temp = eph_temp_split[0::6]\n",
    "    temp_2=temp[i]\n",
    "    #print(temp_2)\n",
    "    eph_split_again,atomic_time= temp_2.split('\\n')\n",
    "    atomic_times.append(np.float(atomic_time))\n",
    "    eph_split_fix.append(np.float(eph_split_again))\n",
    "eph_split_fix.append(np.float(eph_temp_split[-1]))\n",
    "\n",
    "\n",
    "eph_split_fix.insert(0,0)\n",
    "#eph_split_fix.append(0)\n",
    "\n",
    "# Can we omit this?\n",
    "eph_temp_split[0::6]=eph_split_fix\n",
    "\n",
    "for i in range(0,len(eph_temp_split)):\n",
    "    eph_temp_split[i]=np.float(eph_temp_split[i])\n",
    "\n",
    "eph_Adam=eph_temp_split[1:len(eph_temp_split)]\n",
    "\n",
    "#changeeph_Adam from long list to list of 6 elements of statevector\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "eph_Adam_vectors=[]\n",
    "for group in chunker(eph_Adam, 6):\n",
    "    eph_Adam_vectors.append((group))\n",
    "    \n",
    "eph_Adam_x=[]\n",
    "eph_Adam_y=[]\n",
    "eph_Adam_z=[]\n",
    "eph_Adam_xdot=[]\n",
    "eph_Adam_ydot=[]\n",
    "eph_Adam_zdot=[]\n",
    "for i in range(0,len(eph_Adam_vectors)):\n",
    "    temp=eph_Adam_vectors[i]\n",
    "    eph_Adam_x.append(temp[0])\n",
    "    eph_Adam_y.append(temp[1])\n",
    "    eph_Adam_z.append(temp[2])\n",
    "    eph_Adam_xdot.append(temp[3])\n",
    "    eph_Adam_ydot.append(temp[4])\n",
    "    eph_Adam_zdot.append(temp[5])\n",
    "#############################################################################\n",
    "\n",
    "#Construct ADAM dataframe for the JPL state vector\n",
    "eph_Adam_vectors = pd.DataFrame(\n",
    "    {'Time [Atomic UTC]': atomic_times,\n",
    "     'x [m]': eph_Adam_x,\n",
    "     'y [m]': eph_Adam_y,\n",
    "     'z [m]': eph_Adam_z,\n",
    "     'x_dot [m/s]': eph_Adam_xdot,\n",
    "     'y_dot [m/s]': eph_Adam_ydot,\n",
    "     'z_dot [m/s]': eph_Adam_zdot\n",
    "     \n",
    "    })\n",
    "\n",
    " # This line below constructs a seperate dataframe for RIC calculations.  \n",
    " # It's somewhate redundant, but helps keep track of which data we're using.  \n",
    "eph_JPLtoAdam_df = pd.DataFrame(\n",
    "    {'Time [Atomic UTC]': atomic_times,\n",
    "     'x [m]': eph_Adam_x,\n",
    "     'y [m]': eph_Adam_y,\n",
    "     'z [m]': eph_Adam_z,\n",
    "     'x_dot [m/s]': eph_Adam_xdot,\n",
    "     'y_dot [m/s]': eph_Adam_ydot,\n",
    "     'z_dot [m/s]': eph_Adam_zdot\n",
    "     \n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (At this point, you can skip to any function in the notebook.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Orbits for JPL and ADAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize ADAM and JPL orbits for the object.\n",
    "\n",
    "# Let's just do Earth and object for now, this could be expanded to show other planets. \n",
    "earth = Horizons(id='Geocenter', location=None, epochs={'start':start_time_str, 'stop':end_time_str, 'step':'1d'}, id_type = 'majorbody')\n",
    "vEarth = earth.vectors()\n",
    "#sun = Horizons(id='Sun', location=None, epochs={'start':start_time_str, 'stop':end_time_str, 'step':'1d'}, id_type = 'majorbody')\n",
    "#vSun = sun.vectors()\n",
    "\n",
    "#  Get the points for JPL object   \n",
    "n = len(eph_JPL_df)\n",
    "xObj = [1]*n               # initialize X position array\n",
    "yObj = [1]*n               # initialize Y position array\n",
    "zObj = [1]*n               # initialize Z position array\n",
    "\n",
    "\n",
    "for i in range(0,n):             \n",
    "            xObj[i] = eph_JPL_df['x [m]'][i]\n",
    "            yObj[i] = eph_JPL_df['y [m]'][i]\n",
    "            zObj[i] = eph_JPL_df['z [m]'][i]           \n",
    "            \n",
    "#  Get the points for ADAM object            \n",
    "n = len(eph_Adam_vectors)           \n",
    "xADAM_Obj = [1]*n               # initialize X position array\n",
    "yADAM_Obj = [1]*n               # initialize Y position array\n",
    "zADAM_Obj = [1]*n               # initialize Z position array\n",
    "for i in range(0,n):             \n",
    "            xADAM_Obj[i] = eph_Adam_vectors['x [m]'][i]\n",
    "            yADAM_Obj[i] = eph_Adam_vectors['y [m]'][i]\n",
    "            yADAM_Obj[i] = eph_Adam_vectors['z [m]'][i]\n",
    "            \n",
    "# Earth points  \n",
    "n = len(vEarth)\n",
    "xEarth = [1]*n               # initialize X position array\n",
    "yEarth = [1]*n               # initialize Y position array\n",
    "zEarth = [1]*n               # initialize Z position array\n",
    "for i in range(0,n):             \n",
    "            xEarth[i] = (vEarth['x'][i]*AU_Meters)\n",
    "            yEarth[i] = (vEarth['y'][i]*AU_Meters)\n",
    "            zEarth[i] = (vEarth['z'][i]*AU_Meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (In Development) Transform ADAM Vectors from EMEME2000 to ICRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(eph_Adam_vectors) #len(ADAM_ICRF)    \n",
    "\n",
    "\n",
    "#Initialized transformed values\n",
    "TxvUdo = []             # initialize X position array\n",
    "TyvUdo = []              # initialize Y position array\n",
    "TzvUdo = []              # initialize Z position array\n",
    "\n",
    "for i in range (n):\n",
    "    # Transforms ADAM positions from EMEME2000 to ICRF\n",
    "    eph_ADAM_ICRF_temp = Transform.EMEME2000_to_ICRF(eph_Adam_vectors['x [m]'][i],eph_Adam_vectors['y [m]'][i],eph_Adam_vectors['z [m]'][i])       \n",
    "    #eph_ADAM_ICRF_temp = Transform.ICRF_to_EMEME2000(eph_Adam_vectors['x [m]'][i],eph_Adam_vectors['y [m]'][i],eph_Adam_vectors['z [m]'][i])        \n",
    "    # Pulls, X, Y, and Z values   \n",
    "    TxvUdo.append(eph_ADAM_ICRF_temp[0])\n",
    "    TyvUdo.append(eph_ADAM_ICRF_temp[1])\n",
    "    TzvUdo.append(eph_ADAM_ICRF_temp[2])\n",
    "    \n",
    "    \n",
    "    #eph_Adam_vectors['x [m/s]'][i] = eph_ADAM_ICRF_temp[0]\n",
    "    #eph_Adam_vectors['y [m/s]'][i] = eph_ADAM_ICRF_temp[1]\n",
    "    #eph_Adam_vectors['z [m/s]'][i] = eph_ADAM_ICRF_temp[2]\n",
    "    # For now, we are transforming the coordinates and recording a new variable so that we can compare/troubleshoot.  \n",
    "    #In the future it would be simpler to replace the values as they're transformed, as in the velocity example below.  \n",
    "\n",
    "\n",
    "# Transform velocities also\n",
    "    eph_ADAM_ICRF_temp1 = Transform.EMEME2000_to_ICRF(eph_Adam_vectors['x_dot [m/s]'][i],eph_Adam_vectors['y_dot [m/s]'][i],eph_Adam_vectors['z_dot [m/s]'][i])       \n",
    "    # Pulls, X, Y, and Z velocity values   \n",
    "    #eph_ADAM_ICRF_temp1 = Transform.ICRF_to_EMEME2000(eph_Adam_vectors['x_dot [m/s]'][i],eph_Adam_vectors['y_dot [m/s]'][i],eph_Adam_vectors['z_dot [m/s]'][i])       \n",
    "    \n",
    "    eph_Adam_vectors['x_dot [m/s]'][i] = eph_ADAM_ICRF_temp1[0] \n",
    "    eph_Adam_vectors['y_dot [m/s]'][i] = eph_ADAM_ICRF_temp1[1] \n",
    "    eph_Adam_vectors['z_dot [m/s]'][i] = eph_ADAM_ICRF_temp1[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Plot ADAM and JPL \n",
    "  \n",
    "plot_size = max([np.abs(xObj).max() ]) \n",
    "size = [-plot_size-(plot_size*0.10), plot_size+(plot_size*0.10)]  \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1, projection ='3d')   \n",
    "\n",
    "# Plot JPL Object\n",
    "ax.plot(xObj,yObj,zObj, c = 'orange')\n",
    "\n",
    "#Plot ADAM Object\n",
    "ax.plot(xADAM_Obj,yADAM_Obj,zADAM_Obj,c='red')  \n",
    "\n",
    "#Plot ADAM Trans-to_ICRF Object\n",
    "ax.plot(TxvUdo,TyvUdo,TzvUdo,c='purple')   # In Development\n",
    "\n",
    "#Plot Earth\n",
    "ax.plot(xEarth,yEarth,zEarth,c='blue')\n",
    "\n",
    "\n",
    "ax.text(0.5*plot_size,0.5*plot_size,0.8*plot_size, asteroid + \" JPL\",color='orange')\n",
    "ax.text(0.5*plot_size,0.5*plot_size,0.5*plot_size, \"Earth\",color='blue')\n",
    "ax.text(0.5*plot_size,0.5*plot_size,0.2*plot_size, asteroid + \" ADAM\",color='red')\n",
    "ax.text(0.5*plot_size,0.5*plot_size,1.1*plot_size, asteroid + \" ADAM Transformed\",color='purple')\n",
    "#ax.text(0,1.5,2.3, asteroid + \" ADAM in ICRF\",color='purple')   # In development\n",
    "\n",
    "ax.set_xlim(size), ax.set_ylim(size), ax.set_zlim(size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cells allow you to export the ADAM data to .csv and STK formats. (Can be run multiple times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export ADAM or JPL data to CSV(Excel)\n",
    "\n",
    "OutputMethod = input(    'Enter 1 to export ADAM data, enter 2 to export JPL Data')\n",
    "OutputMethod = int(OutputMethod)\n",
    "print(\"This will default export location to your adam_home folder, you can modify this in the cell\") \n",
    "CSV_name = input(\"Enter file name\")\n",
    "CSV_export  = adam_home_defined + \"/\" +CSV_name+'.csv'\n",
    "\n",
    "if OutputMethod == 1 :\n",
    "    #pd.DataFrame(eph_ADAM_1).to_csv(CSV_expd.DataFrame(eph_Adam_vectors).to_csv(CSV_export)port)\n",
    "    pd.DataFrame(eph_Adam_vectors).to_csv(CSV_export)  # Export Adam file  \n",
    "elif OutputMethod ==2 :\n",
    "    pd.DataFrame(eph_JPL_df).to_csv(CSV_export)     #Export JPL Data\n",
    "else: \n",
    "    print(\"Input not recognized\")\n",
    "# Note:  This currently pulls the ADAM data prior to coordinate transform.  \n",
    "# Once that function is developed further we'll need to call those data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Ephemeris to STK (In Development)\n",
    "\n",
    "Skip to last cell if you only want to export a .e file without opening STK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"Ephemeris:\")\n",
    "#print(eph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from win32api import GetSystemMetrics\n",
    "#from comtypes.client import CreateObject\n",
    "# Start STK on the desktop (on Microsoft Windows)\n",
    "#uiApplication=CreateObject(\"STK11.Application\")\n",
    "#uiApplication.Visible=True\n",
    "#uiApplication.UserControl=True\n",
    "\n",
    "#root = uiApplication.Personality2\n",
    "#stk_app = win.gencache.EnsureDispatch('STK11.Application')\n",
    "#stk_app.Visible = True\n",
    "#print(stk_app.__module__)\n",
    "\n",
    "#STK = stk_app.Personality\n",
    "#root = stk_app.Personality2\n",
    "#from comtypes.gen import STKUtil\n",
    "#from comtypes.gen import STKObjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#root.NewScenario(\"ADAM_Starter\")\n",
    "#scenario = root.CurrentScenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Scenario Time   If you changed default times above you'll need to manually format them here. \n",
    "#scenario2 = scenario.QueryInterface(STKObjects.IAgScenario)\n",
    "#scenario2.SetTimePeriod('04 Oct 2016 16:00:05.000', '04 Oct 2017 16:00:05.000')\n",
    "#root.Rewind();\n",
    "#Default Start times\n",
    "#start_time_str='2016-10-04T00:00:00' #YYYY-Mon-Dy {HH:MM}   #Default: start_time_str='2016-10-04T00:00:00'\n",
    "#end_time_str='2017-10-11T00:00:00' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From AGI Help\n",
    "#3. Add a Satellite object to the scenario.\n",
    "#satellite = scenario.Children.New(STKObjects.eSatellite, \"LeoSat\")\n",
    "#4. Propagate the Satellite object's orbit.\n",
    "#root.ExecuteCommand('SetState */Satellite/LeoSat Classical TwoBody \"' + scenario2.StartTime + '\" \"'+ scenario2.StopTime +'\" 60 ICRF \"'+ scenario2.StartTime + '\" 7200000.0 0.0 90 0.0 0.0 0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use STK MTO (Multi Track Object) to store epehmeris points in STK\n",
    "#mto = root.CurrentScenario.Children('ADAM_Starter')\n",
    "#root.ExecuteCommand('VO */MTO/AsteroidTracks System \"CentralBody/Sun Inertial\"')\n",
    "#newMTO = mto.CopyObject('Temp') # satName)\n",
    "\n",
    "    # Add ephemeris file as MTO track\n",
    "#    newTrack = mto.Tracks.Add(countNum)\n",
    "#    newTrack.Points.LoadPoints(os.getcwd() + '/' + fileName)\n",
    "    \n",
    "    # Set graphics properties of track\n",
    " #   newTrack.Interpolate = True\n",
    "  #  mto.Graphics.Tracks.GetTrackFromId(countNum).Line.Width = 1\n",
    "   # mto.Graphics.Tracks.GetTrackFromId(countNum).Color = 0xe16941 # Blue Green Red: 225 105 065\n",
    "  #  mto.Graphics.Tracks.GetTrackFromId(countNum).Line.Translucency = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Skip to here to export .e file without opening STK. \n",
    "\n",
    "# Save ephemeris to STK \".e\" files, and add as track to MTO object in STK\n",
    "print(\"This saves a .e file to the adam_home folder\")\n",
    "print(\"WARNING: This will over-write a file with the same name\")\n",
    "countNum = input(\"Enter file number to save to STK format, (as an integer)\")\n",
    "countNum = int(countNum)\n",
    "satName = asteroid\n",
    "satName = str(satName)\n",
    "    #Write ephemeris to file\n",
    "#eph = b.get_results().get_parts()[0].get_ephemeris()\n",
    "satName = '{:04d}'.format(countNum)\n",
    "fileName = '{}.e'.format(satName)\n",
    "print('STK satellite object name: {}    Ephemeris File Name: {}'.format(satName,fileName))\n",
    "with open(fileName, 'w') as f:\n",
    "        f.write(eph)\n",
    "       \n",
    "    \n",
    "    # Add ephemeris file as MTO track\n",
    "#newTrack = mto.Tracks.Add(countNum)\n",
    "#newTrack.Points.LoadPoints(os.getcwd() + '/' + fileName)\n",
    "    \n",
    "    # Set graphics properties of track\n",
    "#newTrack.Interpolate = True\n",
    "#mto.Graphics.Tracks.GetTrackFromId(countNum).Line.Width = 1\n",
    "#mto.Graphics.Tracks.GetTrackFromId(countNum).Color = 0xe16941 # Blue Green Red: 225 105 065\n",
    "#mto.Graphics.Tracks.GetTrackFromId(countNum).Line.Translucency = 33\n",
    "    \n",
    "    # Increment count for unique ephemeris and STK satellite object name\n",
    "#countNum = countNum + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot RIC for JPL vs ADAM  (Requires Validation after coordinate transfer is functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform ADAM coordinates from EMEME2000 to ICRF Coordinate System\n",
    "n = len(eph_Adam_vectors)\n",
    "\n",
    "for i in range (n):\n",
    "    # Transforms ADAM positions from EMEME2000 to ICRF\n",
    "    eph_ADAM_ICRF_temp1 = Transform.EMEME2000_to_ICRF(eph_JPLtoAdam_df['x [m]'][i],eph_JPLtoAdam_df['y [m]'][i],eph_JPLtoAdam_df['z [m]'][i])       \n",
    "    # Pulls, X, Y, and Z values   \n",
    "    eph_JPLtoAdam_df['x [m]'][i] = eph_ADAM_ICRF_temp1[0] \n",
    "    eph_JPLtoAdam_df['y [m]'][i] = eph_ADAM_ICRF_temp1[1] \n",
    "    eph_JPLtoAdam_df['z [m]'][i] = eph_ADAM_ICRF_temp1[1] \n",
    "\n",
    "# Transform velocities also\n",
    "    eph_ADAM_ICRF_temp2 = Transform.EMEME2000_to_ICRF(eph_JPLtoAdam_df['x_dot [m/s]'][i],eph_JPLtoAdam_df['y_dot [m/s]'][i],eph_JPLtoAdam_df['z_dot [m/s]'][i])       \n",
    "    # Pulls, X, Y, and Z values   \n",
    "    eph_JPLtoAdam_df['x_dot [m/s]'][i] = eph_ADAM_ICRF_temp2[0] \n",
    "    eph_JPLtoAdam_df['y_dot [m/s]'][i] = eph_ADAM_ICRF_temp2[1] \n",
    "    eph_JPLtoAdam_df['z_dot [m/s]'][i] = eph_ADAM_ICRF_temp2[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original  \n",
    "# Organize data from JPL and ADAM for RIC comparisions.  \n",
    "\n",
    "# Need to confirm these calcuations once coordinate transdform is fixed. \n",
    "JPL_R = np.array([np.array(eph_JPL_df.iloc[i,4:7])/np.linalg.norm(eph_JPL_df.iloc[i,4:7]) for i in range(0,len(eph_JPL_df))])\n",
    "JPLtoADAM_R = np.array([np.array(eph_JPLtoAdam_df.iloc[i,1:4])/np.linalg.norm(eph_JPLtoAdam_df.iloc[i,1:4]) for i in range(0,len(eph_JPLtoAdam_df))])\n",
    "\n",
    "##\n",
    "JPL_ADAM_RIC_R = np.array([(JPLtoADAM_R[i]-JPL_R[i])/np.linalg.norm(JPLtoADAM_R[i]-JPL_R[i]) for i in range(0,len(JPL_R))])\n",
    "#print(JPL_ADAM_RIC_R)\n",
    "JPL_V = np.array([np.array(eph_JPL_df.iloc[i,4:7])/np.sqrt(np.sum(np.square(eph_JPL_df.iloc[i,4:7]))) for i in range(0,len(eph_JPL_df))])\n",
    "\n",
    "JPLtoADAM_V = np.array([np.array(eph_JPLtoAdam_df.iloc[i,4:7])/np.sqrt(np.sum(np.square(eph_JPLtoAdam_df.iloc[i,4:7]))) for i in range(0,len(eph_JPLtoAdam_df))])\n",
    "\n",
    "##\n",
    "JPL_ADAM_RIC_V = np.array([(JPLtoADAM_V[i]-JPL_V[i])/np.linalg.norm(JPLtoADAM_V[i]-JPL_V[i]) for i in range(0,len(JPL_R))])\n",
    "#print(JPL_ADAM_RIC_V)\n",
    "\n",
    "JPL_ADAM_RIC_C = np.array([np.cross(JPL_ADAM_RIC_R[i],JPL_ADAM_RIC_V[i]/np.linalg.norm(np.cross(JPL_ADAM_RIC_R[i],JPL_ADAM_RIC_V[i]))) for i in range(0,len(JPL_R))])\n",
    "#JPL_ADAM_RIC_C\n",
    "\n",
    "JPL_ADAM_RIC_I = np.array([np.cross(JPL_ADAM_RIC_R[i],JPL_ADAM_RIC_C[i]/np.linalg.norm(np.cross(JPL_ADAM_RIC_R[i],JPL_ADAM_RIC_C[i]))) for i in range(0,len(JPL_R))])\n",
    "#JPL_ADAM_RIC_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atomic_times=atomic_times[0:len(atomic_times)-1]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.grid(True,ls='--')\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_R[:,0],linewidth=3,label=\"Radial\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_I[:,0],linewidth=3,label=\"Cross Track\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_C[:,0],linewidth=3,label=\"In Track\")\n",
    "plt.title(\"RIC for JPL vs ADAM (along x)\")\n",
    "plt.xlabel('Atomic Time')\n",
    "# confirm?  needs units\n",
    "plt.ylabel('Error in Position')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_R[:,1],linewidth=3,label=\"Radial\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_I[:,1],linewidth=3,label=\"Cross Track\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_C[:,1],linewidth=3,label=\"In Track\")\n",
    "plt.grid(True)\n",
    "plt.title(\"RIC for JPL vs ADAM (along y)\")\n",
    "plt.xlabel('Atomic Time')\n",
    "# confirm?  needs units\n",
    "plt.ylabel('Error in Position')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_R[:,2],linewidth=3,label=\"Radial\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_I[:,2],linewidth=3,label=\"Cross Track\")\n",
    "plt.plot(atomic_times,JPL_ADAM_RIC_C[:,2],linewidth=3,label=\"In Track\")\n",
    "plt.title(\"RIC for JPL vs ADAM (along z)\")\n",
    "plt.grid(True)\n",
    "plt.xlabel('Atomic Time')\n",
    "# confirm?  needs units\n",
    "plt.ylabel('Error in Position')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(atomic_times[0:len(atomic_times)-1])   # for troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "\n",
    "# What is the scale of vertical axis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently Asked Questions (FAQs)\n",
    "\n",
    "How to install Astroquery?  \n",
    "   To install Astroquery, pip install --pre astroquery     \n",
    "More details can be found at astroquery.jplhorizons https://astroquery.readthedocs.io/en/latest/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
